{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Installing the requirements"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-06-08T11:06:28.845015Z",
     "end_time": "2023-06-08T11:06:31.000328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: sentence-transformers in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.2.2)\r\n",
      "Requirement already satisfied: scipy in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.10.1)\r\n",
      "Requirement already satisfied: Levenshtein in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.21.0)\r\n",
      "Requirement already satisfied: fuzzywuzzy in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.18.0)\r\n",
      "Requirement already satisfied: transformers in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (4.29.2)\r\n",
      "Requirement already satisfied: spacy in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (3.5.3)\r\n",
      "Requirement already satisfied: yake in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.4.8)\r\n",
      "Requirement already satisfied: multi_rake in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.0.2)\r\n",
      "Requirement already satisfied: keybert in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.7.0)\r\n",
      "Requirement already satisfied: num2words in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.5.12)\r\n",
      "Requirement already satisfied: gradio in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (3.33.1)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (2.0.1)\r\n",
      "Requirement already satisfied: numpy in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (1.24.3)\r\n",
      "Requirement already satisfied: torchvision in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (0.15.2)\r\n",
      "Requirement already satisfied: tqdm in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (4.65.0)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (1.2.2)\r\n",
      "Requirement already satisfied: nltk in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (3.8.1)\r\n",
      "Requirement already satisfied: sentencepiece in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (0.1.99)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from sentence-transformers->-r requirements.txt (line 1)) (0.15.1)\r\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from Levenshtein->-r requirements.txt (line 3)) (3.1.1)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 5)) (0.13.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 5)) (23.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 5)) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 5)) (2023.6.3)\r\n",
      "Requirement already satisfied: filelock in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 5)) (3.12.0)\r\n",
      "Requirement already satisfied: requests in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 5)) (2.29.0)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 6)) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 6)) (3.0.8)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 6)) (1.0.4)\r\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 6)) (8.1.10)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 6)) (1.0.9)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 6)) (2.4.6)\r\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 6)) (0.7.0)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 6)) (3.3.0)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 6)) (1.1.2)\r\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 6)) (0.10.1)\r\n",
      "Requirement already satisfied: setuptools in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 6)) (67.8.0)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 6)) (3.0.12)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 6)) (2.0.7)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 6)) (6.3.0)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 6)) (1.10.8)\r\n",
      "Requirement already satisfied: jinja2 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from spacy->-r requirements.txt (line 6)) (3.1.2)\r\n",
      "Requirement already satisfied: segtok in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from yake->-r requirements.txt (line 7)) (1.5.11)\r\n",
      "Requirement already satisfied: click>=6.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from yake->-r requirements.txt (line 7)) (8.1.3)\r\n",
      "Requirement already satisfied: tabulate in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from yake->-r requirements.txt (line 7)) (0.9.0)\r\n",
      "Requirement already satisfied: networkx in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from yake->-r requirements.txt (line 7)) (3.1)\r\n",
      "Requirement already satisfied: jellyfish in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from yake->-r requirements.txt (line 7)) (0.11.2)\r\n",
      "Requirement already satisfied: pyrsistent>=0.14.2 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from multi_rake->-r requirements.txt (line 8)) (0.18.0)\r\n",
      "Requirement already satisfied: pycld2>=0.41 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from multi_rake->-r requirements.txt (line 8)) (0.41)\r\n",
      "Requirement already satisfied: rich>=10.4.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from keybert->-r requirements.txt (line 9)) (13.4.1)\r\n",
      "Requirement already satisfied: docopt>=0.6.2 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from num2words->-r requirements.txt (line 10)) (0.6.2)\r\n",
      "Requirement already satisfied: markupsafe in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (2.1.1)\r\n",
      "Requirement already satisfied: pydub in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (0.25.1)\r\n",
      "Requirement already satisfied: ffmpy in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (0.3.0)\r\n",
      "Requirement already satisfied: pygments>=2.12.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (2.15.1)\r\n",
      "Requirement already satisfied: matplotlib in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (3.7.1)\r\n",
      "Requirement already satisfied: orjson in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (3.9.0)\r\n",
      "Requirement already satisfied: pillow in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (9.5.0)\r\n",
      "Requirement already satisfied: python-multipart in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (0.0.6)\r\n",
      "Requirement already satisfied: altair>=4.2.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (5.0.1)\r\n",
      "Requirement already satisfied: aiofiles in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (23.1.0)\r\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (2.2.0)\r\n",
      "Requirement already satisfied: websockets>=10.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (11.0.3)\r\n",
      "Requirement already satisfied: aiohttp in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (3.8.4)\r\n",
      "Requirement already satisfied: pandas in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (2.0.2)\r\n",
      "Requirement already satisfied: gradio-client>=0.2.4 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (0.2.5)\r\n",
      "Requirement already satisfied: fastapi in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (0.96.0)\r\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (0.3.3)\r\n",
      "Requirement already satisfied: httpx in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (0.24.1)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (4.5.0)\r\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (0.22.0)\r\n",
      "Requirement already satisfied: semantic-version in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (2.10.0)\r\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 11)) (4.17.3)\r\n",
      "Requirement already satisfied: toolz in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 11)) (0.12.0)\r\n",
      "Requirement already satisfied: fsspec in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from gradio-client>=0.2.4->gradio->-r requirements.txt (line 11)) (2023.5.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 11)) (0.1.2)\r\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 11)) (2.0.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from pandas->gradio->-r requirements.txt (line 11)) (2022.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from pandas->gradio->-r requirements.txt (line 11)) (2.8.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from pandas->gradio->-r requirements.txt (line 11)) (2023.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 5)) (2023.5.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 5)) (1.26.15)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 5)) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 5)) (3.4)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 1)) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 1)) (3.1.0)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy->-r requirements.txt (line 6)) (0.0.4)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy->-r requirements.txt (line 6)) (0.7.9)\r\n",
      "Requirement already satisfied: sympy in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers->-r requirements.txt (line 1)) (1.12)\r\n",
      "Requirement already satisfied: h11>=0.8 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 11)) (0.14.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from aiohttp->gradio->-r requirements.txt (line 11)) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from aiohttp->gradio->-r requirements.txt (line 11)) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from aiohttp->gradio->-r requirements.txt (line 11)) (1.3.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from aiohttp->gradio->-r requirements.txt (line 11)) (22.1.0)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from aiohttp->gradio->-r requirements.txt (line 11)) (4.0.2)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from aiohttp->gradio->-r requirements.txt (line 11)) (1.3.1)\r\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from fastapi->gradio->-r requirements.txt (line 11)) (0.27.0)\r\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from httpx->gradio->-r requirements.txt (line 11)) (0.17.2)\r\n",
      "Requirement already satisfied: sniffio in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from httpx->gradio->-r requirements.txt (line 11)) (1.2.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from matplotlib->gradio->-r requirements.txt (line 11)) (3.0.9)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from matplotlib->gradio->-r requirements.txt (line 11)) (1.4.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from matplotlib->gradio->-r requirements.txt (line 11)) (1.0.7)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from matplotlib->gradio->-r requirements.txt (line 11)) (4.39.4)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from matplotlib->gradio->-r requirements.txt (line 11)) (0.11.0)\r\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio->-r requirements.txt (line 11)) (3.5.0)\r\n",
      "Requirement already satisfied: uc-micro-py in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 11)) (1.0.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->gradio->-r requirements.txt (line 11)) (1.16.0)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/lucas/opt/miniconda3/envs/DialoKEY_Codebase/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers->-r requirements.txt (line 1)) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "import random\n",
    "from keybert import KeyBERT\n",
    "from multi_rake import Rake\n",
    "import yake\n",
    "import os\n",
    "import collections\n",
    "import json\n",
    "# import num2words\n",
    "import re\n",
    "import datetime\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T11:06:30.999933Z",
     "end_time": "2023-06-08T11:06:31.001734Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setups"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Keyword Extractors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "dt = datetime.datetime.now()\n",
    "timestamp = dt.strftime('%Y_%m_%d_%H:%M:%S')[:-3]\n",
    "\n",
    "kw_model = KeyBERT(model='all-mpnet-base-v2')\n",
    "\n",
    "\n",
    "def kw_yake(text):\n",
    "    # kw_extractor = yake.KeywordExtractor()\n",
    "    language = \"en\"\n",
    "    max_ngram_size = 1\n",
    "    deduplication_threshold = 0.9\n",
    "    numOfKeywords = 10\n",
    "    custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold,\n",
    "                                                top=numOfKeywords, features=None)\n",
    "    keywords = custom_kw_extractor.extract_keywords(text)\n",
    "    keywords_str = \"\"\n",
    "    for index, keyword in enumerate(keywords):\n",
    "        if index == len(keywords) - 1:\n",
    "            keywords_str += f\"{keyword[0]}\"\n",
    "        else:\n",
    "            keywords_str += f\"{keyword[0]} \"\n",
    "    return keywords_str\n",
    "\n",
    "\n",
    "def kw_yake_detailed(text):\n",
    "    language = \"en\"\n",
    "    max_ngram_size = 5\n",
    "    deduplication_threshold = 0.0\n",
    "    numOfKeywords = 10\n",
    "    custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold,\n",
    "                                                top=numOfKeywords, features=None)\n",
    "    keywords = custom_kw_extractor.extract_keywords(text)\n",
    "    keywords_str = \"\"\n",
    "    for index, keyword in enumerate(keywords):\n",
    "        if index == len(keywords) - 1:\n",
    "            keywords_str += f\"{keyword[0]}\"\n",
    "        else:\n",
    "            keywords_str += f\"{keyword[0]} \"\n",
    "    return keywords_str\n",
    "\n",
    "\n",
    "def kw_rake(text):\n",
    "    rake = Rake()\n",
    "    keywords = rake.apply(text)\n",
    "    keywords_str = \"\"\n",
    "    for index, keyword in enumerate(keywords):\n",
    "        if index == len(keywords) - 1:\n",
    "            keywords_str += f\"{keyword[0]}\"\n",
    "        else:\n",
    "            keywords_str += f\"{keyword[0]} \"\n",
    "    return (keywords_str)\n",
    "\n",
    "\n",
    "def kw_keybert(text):\n",
    "    keywords = kw_model.extract_keywords(\n",
    "        text,\n",
    "        keyphrase_ngram_range=(1, 7),\n",
    "        stop_words='english',\n",
    "        highlight=False,\n",
    "        top_n=1)\n",
    "    keywords_list = list(dict(keywords).keys())\n",
    "    if not keywords_list:\n",
    "        return \"\"\n",
    "    return (keywords_list[0])\n",
    "\n",
    "\n",
    "def keyword_extractors(text):\n",
    "    keywords = ({\n",
    "        \"KeyBERT\": kw_keybert(text),\n",
    "        \"RAKE\": kw_rake(text),\n",
    "        \"YAKE\": kw_yake(text),\n",
    "        \"YAKE (Detailed)\": kw_yake_detailed(text),\n",
    "    })\n",
    "    return keywords"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T11:06:31.002842Z",
     "end_time": "2023-06-08T11:06:31.963561Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decontraction Function and slicer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    phrase = re.sub(r\"Won\\'t\", \"Will not\", phrase)\n",
    "    phrase = re.sub(r\"Can\\'t\", \"Can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\â€™ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "list_negations = [\n",
    "    \" not \",\n",
    "    \" not.\",\n",
    "    \" no \",\n",
    "    \" no.\"\n",
    "]\n",
    "\n",
    "def slicer(my_str, sub):\n",
    "    index = my_str.find(sub)\n",
    "    if index != -1:\n",
    "        return my_str[index + len(sub):]\n",
    "    else:\n",
    "        raise Exception('Sub string not found!')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T11:06:31.968028Z",
     "end_time": "2023-06-08T11:06:31.969626Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Folder Paths and reading the raw files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./txt_conversations/1. Visiting a Travel Agent.txt\n",
      "./txt_conversations/1. I Feel Like Chinese.txt\n",
      "./txt_conversations/1. Making Plans for the Weekend.txt\n",
      "./txt_conversations/1. I Go to College.txt\n",
      "./txt_conversations/1. Looking for a Job.txt\n",
      "./txt_conversations/1. Too Much Crime.txt\n",
      "./txt_conversations/1. Which Bus to Take (1).txt\n",
      "./txt_conversations/1. I Live in Pasadena.txt\n",
      "./txt_conversations/1. What Will People Think.txt\n",
      "./txt_conversations/1. Unemployment Insurance.txt\n"
     ]
    }
   ],
   "source": [
    "folderpath = r\"./txt_conversations\"  # make sure to put the 'r' in front\n",
    "folderpath_stripped = folderpath.replace(\"./\",\"\")\n",
    "\n",
    "filepaths = [os.path.join(folderpath, name) for name in os.listdir(folderpath)]\n",
    "all_files = []\n",
    "\n",
    "for path in filepaths:\n",
    "    print(path)\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            file = f.readlines()\n",
    "            all_files.append(file)\n",
    "    except:\n",
    "        print(\"EXCEPTION\" + path)\n",
    "        continue\n",
    "\n",
    "files_as_text = []\n",
    "for elements in all_files:\n",
    "    text = \"\"\n",
    "    for lines in elements:\n",
    "        try:\n",
    "            text += lines\n",
    "        except:\n",
    "            print(\"Exception in all files\")\n",
    "            continue\n",
    "    files_as_text.append(text)\n",
    "\n",
    "with open('./output_files/all_text.json', mode='w', encoding='utf-8') as feedsjson2:\n",
    "    json.dump(all_files, feedsjson2)\n",
    "\n",
    "with open('./output_files/all_text_array.json', mode='w', encoding='utf-8') as feedsjson3:\n",
    "    json.dump(files_as_text, feedsjson3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T11:06:31.972678Z",
     "end_time": "2023-06-08T11:06:31.977814Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Declaring variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "feeds = collections.defaultdict(list)\n",
    "feeds2 = []\n",
    "current = \"\"\n",
    "files_total = 0\n",
    "lines_total = 0\n",
    "skipped = 0\n",
    "not_skipped_answers = 0\n",
    "skipped_too_long = 0\n",
    "skipped_too_long_cache = 0\n",
    "not_skipped_questions = 0\n",
    "empty_line = 0\n",
    "keywords_counter = ({\n",
    "        \"KeyBERT\": 0,\n",
    "        \"RAKE\": 0,\n",
    "        \"YAKE\": 0,\n",
    "        'YAKE_DETAILED': 0\n",
    "    })\n",
    "\n",
    "history_counter = ({\n",
    "        \"0\": 0,\n",
    "        \"1\": 0,\n",
    "        \"2\": 0,\n",
    "        '3': 0\n",
    "    })\n",
    "\n",
    "length = len(all_files)\n",
    "counter_1 = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T11:06:31.980799Z",
     "end_time": "2023-06-08T11:06:31.982396Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Iterating through all files and create the dataset structure"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________## 10.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', 'A: Thank you for coming to our travel agency. How can I help you?\\n', 'B: I would like to book a trip to Disney World for my family.\\n', 'A: Your family will have much fun. When do you want to go?\\n', 'B: We want to go during the summer when the kids have off from school.\\n', \"A: I suggest early June because it won't rain too much and the park isn't as crowded as later in the season.\\n\", \"B: Great! let's do the second week in June.\\n\", 'A: How many adults and how many children will be travelling?\\n', 'B: There are two adults and two children.\\n', 'A: Do you have an airline preference?\\n', 'B: No. I have no preference as long as the flight is non-stop.\\n', 'A: Do you want a budget hotel or a luxury hotel?\\n', 'B: Can you book something in between?\\n', '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', 'A: Thank you for coming to our travel agency. How can I help you?\\n', 'B: I would like to book a trip to Disney World for my family.\\n', 'A: Your family will have much fun. When do you want to go?\\n', 'B: We want to go during the summer when the kids have off from school.\\n', \"A: I suggest early June because it won't rain too much and the park isn't as crowded as later in the season.\\n\", \"B: Great! let's do the second week in June.\\n\", 'A: How many adults and how many children will be travelling?\\n', 'B: There are two adults and two children.\\n', 'A: Do you have an airline preference?\\n', 'B: No. I have no preference as long as the flight is non-stop.\\n', 'A: Do you want a budget hotel or a luxury hotel?\\n', 'B: Can you book something in between?\\n', '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', 'A: Thank you for coming to our travel agency. How can I help you?\\n', 'B: I would like to book a trip to Disney World for my family.\\n', 'A: Your family will have much fun. When do you want to go?\\n', 'B: We want to go during the summer when the kids have off from school.\\n', \"A: I suggest early June because it won't rain too much and the park isn't as crowded as later in the season.\\n\", \"B: Great! let's do the second week in June.\\n\", 'A: How many adults and how many children will be travelling?\\n', 'B: There are two adults and two children.\\n', 'A: Do you have an airline preference?\\n', 'B: No. I have no preference as long as the flight is non-stop.\\n', 'A: Do you want a budget hotel or a luxury hotel?\\n', 'B: Can you book something in between?\\n', '\\n', '\\n'] +++\n",
      "______________## 20.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', \"A: Let's go out to eat.\\n\", 'B: That sounds like fun.\\n', 'A: Where do you want to go?\\n', 'B: Let me think a minute.\\n', 'A: I feel like Chinese.\\n', 'B: That sounds delicious.\\n', 'A: I know a good Chinese restaurant.\\n', 'B: How far away is it?\\n', \"A: It's only 10 minutes from here.\\n\", 'B: Do we need reservations?\\n', 'A: Oh, no. We can walk right in.\\n', \"B: Let's go now. I'm hungry!\\n\", '\\n', '\\n'] +++\n",
      "+++ Keyword Extraction -> Empty Result +++\n",
      "+++ KW FOUND +++ (By another extraxtor)\n",
      "+++ Empty Line found in ['\\n', \"A: Let's go out to eat.\\n\", 'B: That sounds like fun.\\n', 'A: Where do you want to go?\\n', 'B: Let me think a minute.\\n', 'A: I feel like Chinese.\\n', 'B: That sounds delicious.\\n', 'A: I know a good Chinese restaurant.\\n', 'B: How far away is it?\\n', \"A: It's only 10 minutes from here.\\n\", 'B: Do we need reservations?\\n', 'A: Oh, no. We can walk right in.\\n', \"B: Let's go now. I'm hungry!\\n\", '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', \"A: Let's go out to eat.\\n\", 'B: That sounds like fun.\\n', 'A: Where do you want to go?\\n', 'B: Let me think a minute.\\n', 'A: I feel like Chinese.\\n', 'B: That sounds delicious.\\n', 'A: I know a good Chinese restaurant.\\n', 'B: How far away is it?\\n', \"A: It's only 10 minutes from here.\\n\", 'B: Do we need reservations?\\n', 'A: Oh, no. We can walk right in.\\n', \"B: Let's go now. I'm hungry!\\n\", '\\n', '\\n'] +++\n",
      "______________## 30.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', 'A: What are you going to do this weekend?\\n', \"B: I haven't made any solid plans yet. Why do you ask?\\n\", \"A: There's this event at a bookstore downtown I was thinking of checking out.\\n\", 'B: That sounds really interesting.\\n', \"A: Yeah, and even if it's not, we can leave and grab a bite.\\n\", 'B: There are so many nice new places that have opened up downtown.\\n', 'A: I know, and have wanted to try them all.\\n', 'B: So our meeting time is Saturday at three.\\n', \"A: I'll meet you at the bookstore.\\n\", \"B: It's the bookstore on Spring Street.\\n\", 'A: We can grab some food and drinks after.\\n', 'B: An early dinner sounds great.\\n', '\\n', '\\n'] +++\n",
      "??? Question in the first line ???\n",
      "+++ Empty Line found in ['\\n', 'A: What are you going to do this weekend?\\n', \"B: I haven't made any solid plans yet. Why do you ask?\\n\", \"A: There's this event at a bookstore downtown I was thinking of checking out.\\n\", 'B: That sounds really interesting.\\n', \"A: Yeah, and even if it's not, we can leave and grab a bite.\\n\", 'B: There are so many nice new places that have opened up downtown.\\n', 'A: I know, and have wanted to try them all.\\n', 'B: So our meeting time is Saturday at three.\\n', \"A: I'll meet you at the bookstore.\\n\", \"B: It's the bookstore on Spring Street.\\n\", 'A: We can grab some food and drinks after.\\n', 'B: An early dinner sounds great.\\n', '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', 'A: What are you going to do this weekend?\\n', \"B: I haven't made any solid plans yet. Why do you ask?\\n\", \"A: There's this event at a bookstore downtown I was thinking of checking out.\\n\", 'B: That sounds really interesting.\\n', \"A: Yeah, and even if it's not, we can leave and grab a bite.\\n\", 'B: There are so many nice new places that have opened up downtown.\\n', 'A: I know, and have wanted to try them all.\\n', 'B: So our meeting time is Saturday at three.\\n', \"A: I'll meet you at the bookstore.\\n\", \"B: It's the bookstore on Spring Street.\\n\", 'A: We can grab some food and drinks after.\\n', 'B: An early dinner sounds great.\\n', '\\n', '\\n'] +++\n",
      "______________## 40.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', 'A: Do you go to college?\\n', 'B: Yes, I do.\\n', 'A: What college do you go to?\\n', 'B: I go to Pasadena City College.\\n', 'A: Do you like it?\\n', 'B: Oh, yes, I really like it.\\n', 'A: Why do you like it?\\n', 'B: Because it has great teachers.\\n', 'A: What else?\\n', 'B: I like all my classmates, too.\\n', 'A: Anything else?\\n', \"B: Yes. It's not expensive!\\n\", '\\n', '\\n'] +++\n",
      "+++ Keyword Extraction -> Empty Result +++\n",
      "+++ KW FOUND +++ (By another extraxtor)\n",
      "+++ Empty Line found in ['\\n', 'A: Do you go to college?\\n', 'B: Yes, I do.\\n', 'A: What college do you go to?\\n', 'B: I go to Pasadena City College.\\n', 'A: Do you like it?\\n', 'B: Oh, yes, I really like it.\\n', 'A: Why do you like it?\\n', 'B: Because it has great teachers.\\n', 'A: What else?\\n', 'B: I like all my classmates, too.\\n', 'A: Anything else?\\n', \"B: Yes. It's not expensive!\\n\", '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', 'A: Do you go to college?\\n', 'B: Yes, I do.\\n', 'A: What college do you go to?\\n', 'B: I go to Pasadena City College.\\n', 'A: Do you like it?\\n', 'B: Oh, yes, I really like it.\\n', 'A: Why do you like it?\\n', 'B: Because it has great teachers.\\n', 'A: What else?\\n', 'B: I like all my classmates, too.\\n', 'A: Anything else?\\n', \"B: Yes. It's not expensive!\\n\", '\\n', '\\n'] +++\n",
      "______________## 50.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', \"A: Hey Dennis, this is Ron. How's it going?\\n\", \"B: Hi, Ron. I'm looking for a summer job. I was hoping you could help me.\\n\", 'A: Okay, how can I help you?\\n', 'B: Well, I was wondering if you could hook me up at the place you work.\\n', \"A: No problem. I don't know if they're hiring, but I'll find out.\\n\", \"B: Aw man, you're the bomb!\\n\", 'A: What kind of job you are interested in doing?\\n', 'B: Anything you think that I can do will be fine.\\n', \"A: I'll talk to my boss in the morning and get back to you.\\n\", 'B: Thanks, man. A friend in need is a friend indeed.\\n', 'A: Anything else you need me to do?\\n', \"B: No. I'm waiting to hear from you.\\n\", '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', \"A: Hey Dennis, this is Ron. How's it going?\\n\", \"B: Hi, Ron. I'm looking for a summer job. I was hoping you could help me.\\n\", 'A: Okay, how can I help you?\\n', 'B: Well, I was wondering if you could hook me up at the place you work.\\n', \"A: No problem. I don't know if they're hiring, but I'll find out.\\n\", \"B: Aw man, you're the bomb!\\n\", 'A: What kind of job you are interested in doing?\\n', 'B: Anything you think that I can do will be fine.\\n', \"A: I'll talk to my boss in the morning and get back to you.\\n\", 'B: Thanks, man. A friend in need is a friend indeed.\\n', 'A: Anything else you need me to do?\\n', \"B: No. I'm waiting to hear from you.\\n\", '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', \"A: Hey Dennis, this is Ron. How's it going?\\n\", \"B: Hi, Ron. I'm looking for a summer job. I was hoping you could help me.\\n\", 'A: Okay, how can I help you?\\n', 'B: Well, I was wondering if you could hook me up at the place you work.\\n', \"A: No problem. I don't know if they're hiring, but I'll find out.\\n\", \"B: Aw man, you're the bomb!\\n\", 'A: What kind of job you are interested in doing?\\n', 'B: Anything you think that I can do will be fine.\\n', \"A: I'll talk to my boss in the morning and get back to you.\\n\", 'B: Thanks, man. A friend in need is a friend indeed.\\n', 'A: Anything else you need me to do?\\n', \"B: No. I'm waiting to hear from you.\\n\", '\\n', '\\n'] +++\n",
      "______________## 60.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', 'A: Why is there so much crime?\\n', \"B: Because parents don't teach their kids right from wrong.\\n\", 'A: Is that it?\\n', \"B: Also, there aren't enough police.\\n\", 'A: But there are a lot of police.\\n', \"B: There's only one police officer per 100 criminals.\\n\", \"A: Can't we hire more police?\\n\", 'B: No. It costs too much money.\\n', \"A: Doesn't crime cost more than police?\\n\", 'B: Yes, it does.\\n', 'A: So it would be cheaper to hire more police?\\n', 'B: Yes, it would.\\n', '\\n', '\\n'] +++\n",
      "+++ Keyword Extraction -> Empty Result +++\n",
      "+++ KW FOUND +++ (By another extraxtor)\n",
      "+++ Keyword Extraction -> Empty Result +++\n",
      "+++ KW FOUND +++ (By another extraxtor)\n",
      "+++ Empty Line found in ['\\n', 'A: Why is there so much crime?\\n', \"B: Because parents don't teach their kids right from wrong.\\n\", 'A: Is that it?\\n', \"B: Also, there aren't enough police.\\n\", 'A: But there are a lot of police.\\n', \"B: There's only one police officer per 100 criminals.\\n\", \"A: Can't we hire more police?\\n\", 'B: No. It costs too much money.\\n', \"A: Doesn't crime cost more than police?\\n\", 'B: Yes, it does.\\n', 'A: So it would be cheaper to hire more police?\\n', 'B: Yes, it would.\\n', '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', 'A: Why is there so much crime?\\n', \"B: Because parents don't teach their kids right from wrong.\\n\", 'A: Is that it?\\n', \"B: Also, there aren't enough police.\\n\", 'A: But there are a lot of police.\\n', \"B: There's only one police officer per 100 criminals.\\n\", \"A: Can't we hire more police?\\n\", 'B: No. It costs too much money.\\n', \"A: Doesn't crime cost more than police?\\n\", 'B: Yes, it does.\\n', 'A: So it would be cheaper to hire more police?\\n', 'B: Yes, it would.\\n', '\\n', '\\n'] +++\n",
      "______________## 70.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', 'A: You seem a little lost.\\n', 'B: I actually am lost. How could you tell?\\n', 'A: The look on your face said it all.\\n', 'B: Maybe you could help me.\\n', \"A: I'd be happy to help.\\n\", \"B: I'm not sure what bus I'm supposed to take.\\n\", \"A: What's your destination?\\n\", \"B: I'm heading to Westwood.\\n\", \"A: I've been there several times by bus.\\n\", 'B: You have? What bus did you take?\\n', 'A: The Line 720 takes you directly there.\\n', 'B: Where is the stop for that bus?\\n', 'A: Right at the corner over there.\\n', 'B: Thank you very much.\\n', '\\n', '\\n'] +++\n",
      "??? Question in the first line ???\n",
      "+++ Keyword Extraction -> Empty Result +++\n",
      "+++ KW FOUND +++ (By another extraxtor)\n",
      "+++ Empty Line found in ['\\n', 'A: You seem a little lost.\\n', 'B: I actually am lost. How could you tell?\\n', 'A: The look on your face said it all.\\n', 'B: Maybe you could help me.\\n', \"A: I'd be happy to help.\\n\", \"B: I'm not sure what bus I'm supposed to take.\\n\", \"A: What's your destination?\\n\", \"B: I'm heading to Westwood.\\n\", \"A: I've been there several times by bus.\\n\", 'B: You have? What bus did you take?\\n', 'A: The Line 720 takes you directly there.\\n', 'B: Where is the stop for that bus?\\n', 'A: Right at the corner over there.\\n', 'B: Thank you very much.\\n', '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', 'A: You seem a little lost.\\n', 'B: I actually am lost. How could you tell?\\n', 'A: The look on your face said it all.\\n', 'B: Maybe you could help me.\\n', \"A: I'd be happy to help.\\n\", \"B: I'm not sure what bus I'm supposed to take.\\n\", \"A: What's your destination?\\n\", \"B: I'm heading to Westwood.\\n\", \"A: I've been there several times by bus.\\n\", 'B: You have? What bus did you take?\\n', 'A: The Line 720 takes you directly there.\\n', 'B: Where is the stop for that bus?\\n', 'A: Right at the corner over there.\\n', 'B: Thank you very much.\\n', '\\n', '\\n'] +++\n",
      "______________## 80.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', 'A: Where do you live?\\n', 'B: I live in Pasadena.\\n', 'A: Where is Pasadena?\\n', \"B: It's in California.\\n\", 'A: Is it in northern California?\\n', \"B: No. It's in southern California.\\n\", 'A: Is Pasadena a big city?\\n', \"B: It's pretty big.\\n\", 'A: How big is \"pretty big\"?\\n', 'B: It has about 140,000 people.\\n', 'A: How big is Los Angeles?\\n', 'B: It has about 3 million people.\\n', '\\n', '\\n'] +++\n",
      "+++ Keyword Extraction -> Empty Result +++\n",
      "+++ KW FOUND +++ (By another extraxtor)\n",
      "+++ Empty Line found in ['\\n', 'A: Where do you live?\\n', 'B: I live in Pasadena.\\n', 'A: Where is Pasadena?\\n', \"B: It's in California.\\n\", 'A: Is it in northern California?\\n', \"B: No. It's in southern California.\\n\", 'A: Is Pasadena a big city?\\n', \"B: It's pretty big.\\n\", 'A: How big is \"pretty big\"?\\n', 'B: It has about 140,000 people.\\n', 'A: How big is Los Angeles?\\n', 'B: It has about 3 million people.\\n', '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', 'A: Where do you live?\\n', 'B: I live in Pasadena.\\n', 'A: Where is Pasadena?\\n', \"B: It's in California.\\n\", 'A: Is it in northern California?\\n', \"B: No. It's in southern California.\\n\", 'A: Is Pasadena a big city?\\n', \"B: It's pretty big.\\n\", 'A: How big is \"pretty big\"?\\n', 'B: It has about 140,000 people.\\n', 'A: How big is Los Angeles?\\n', 'B: It has about 3 million people.\\n', '\\n', '\\n'] +++\n",
      "______________## 90.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', \"A: I don't like riding the bus.\\n\", 'B: Why not?\\n', 'A: The seats and windows are dirty.\\n', \"B: Don't they clean the bus every night?\\n\", 'A: I think they do.\\n', 'B: You should bring some wipes with you.\\n', \"A: That's a good idea.\\n\", 'B: Then you can wipe your seat and window.\\n', \"A: People will think I'm strange.\\n\", 'B: Who cares? Everyone is strange.\\n', \"A: That's for sure.\\n\", \"B: Don't worry about what people think.\\n\", '\\n', '\\n'] +++\n",
      "??? Question in the first line ???\n",
      "??? SKIPPED ???\n",
      "______________## 100.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', 'A: Hey Diana, why so glum?\\n', 'B: Aw Bobby, I just lost my job.\\n', 'A: Oh, no. What happened?\\n', 'B: The company is relocating to another state.\\n', \"A: That's tough, Diana. What are you going to do now?\\n\", \"B: I'm looking for a new job. I need to pay my bills.\\n\", 'A: Are you filing for unemployment benefits?\\n', \"B: I don't think I'm eligible. I only worked there three months.\\n\", \"A: Sure, you're eligible. You worked long enough.\\n\", \"B: I didn't know that.\\n\", 'A: I think you only have to work for two weeks to be eligible.\\n', \"B: That's great. I hope I can get it.\\n\", \"A: You'll never know untill you try.\\n\", \"B: Thanks, Bobby. You're a good friend.\\n\", '\\n', '\\n'] +++\n",
      "+++ Keyword Extraction -> Empty Result +++\n",
      "+++ KW FOUND +++ (By another extraxtor)\n",
      "+++ Empty Line found in ['\\n', 'A: Hey Diana, why so glum?\\n', 'B: Aw Bobby, I just lost my job.\\n', 'A: Oh, no. What happened?\\n', 'B: The company is relocating to another state.\\n', \"A: That's tough, Diana. What are you going to do now?\\n\", \"B: I'm looking for a new job. I need to pay my bills.\\n\", 'A: Are you filing for unemployment benefits?\\n', \"B: I don't think I'm eligible. I only worked there three months.\\n\", \"A: Sure, you're eligible. You worked long enough.\\n\", \"B: I didn't know that.\\n\", 'A: I think you only have to work for two weeks to be eligible.\\n', \"B: That's great. I hope I can get it.\\n\", \"A: You'll never know untill you try.\\n\", \"B: Thanks, Bobby. You're a good friend.\\n\", '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', 'A: Hey Diana, why so glum?\\n', 'B: Aw Bobby, I just lost my job.\\n', 'A: Oh, no. What happened?\\n', 'B: The company is relocating to another state.\\n', \"A: That's tough, Diana. What are you going to do now?\\n\", \"B: I'm looking for a new job. I need to pay my bills.\\n\", 'A: Are you filing for unemployment benefits?\\n', \"B: I don't think I'm eligible. I only worked there three months.\\n\", \"A: Sure, you're eligible. You worked long enough.\\n\", \"B: I didn't know that.\\n\", 'A: I think you only have to work for two weeks to be eligible.\\n', \"B: That's great. I hope I can get it.\\n\", \"A: You'll never know untill you try.\\n\", \"B: Thanks, Bobby. You're a good friend.\\n\", '\\n', '\\n'] +++\n"
     ]
    }
   ],
   "source": [
    "for fp in all_files:\n",
    "    counter_1 += 1\n",
    "    print(f\"______________## {(counter_1/length)*100} % ##______________\")\n",
    "    http_in_file = False\n",
    "    for lines in fp:\n",
    "        if \"http\" in lines:\n",
    "            print(\"+++ HTTP IN LINE +++\")\n",
    "            http_in_file = True\n",
    "    files_total += 1\n",
    "    current = \"\"\n",
    "    lines = []\n",
    "    counter = 0\n",
    "    cache = \"\"\n",
    "    cache_happy_transformers = \"\"\n",
    "    cache_array = []\n",
    "    http_here = False\n",
    "\n",
    "    for i, line in enumerate(fp):\n",
    "        ## ALTERNATIVE 1 ##\n",
    "        # For all conversations where the history is longer than 900 chars, the conversation is skipped\n",
    "        # if len(cache) > 900:\n",
    "        #     skipped_too_long_cache +=1\n",
    "        #     continue\n",
    "        ## ALTERNATIVE 1 ##\n",
    "\n",
    "\n",
    "        ## ALTERNATIVE 2 ##\n",
    "        # It is randomly chosen, how long the appended history in a conversation is\n",
    "        # It is never longer than 3 QA-Pairs\n",
    "        if len(cache_array) == 1:\n",
    "            pop_random = random.randint(1, 5)\n",
    "            if pop_random == 1:\n",
    "                cache_array.clear()\n",
    "\n",
    "        if len(cache_array) == 2:\n",
    "            pop_random = random.randint(0, 5)\n",
    "            if pop_random == 1:\n",
    "                cache_array.pop(0)\n",
    "            elif pop_random == 2:\n",
    "                cache_array.pop(0)\n",
    "                cache_array.pop(0)\n",
    "            elif pop_random == 3:\n",
    "                cache_array.clear()\n",
    "\n",
    "        if len(cache_array) > 3:\n",
    "            pop_random = random.randint(1, 3)\n",
    "            if pop_random == 1:\n",
    "                cache_array.pop(0)\n",
    "            elif pop_random == 2:\n",
    "                cache_array.pop(0)\n",
    "                cache_array.pop(0)\n",
    "            elif pop_random == 3:\n",
    "                cache_array.clear()\n",
    "        ## ALTERNATIVE 2 ##\n",
    "\n",
    "        lines_total += 1\n",
    "\n",
    "        # Sometimes there are HTTP links or empty lines in the conversations -> Those are skipped\n",
    "        if http_in_file:\n",
    "            if line == \"\" or line == \"\\n\" or line == \"\\r\" or http_here is False:\n",
    "                if \"http\" in line:\n",
    "                    http_here = True\n",
    "                print(f\"+++ Empty Line found in HTTP  {fp} +++\")\n",
    "                empty_line += 1\n",
    "                continue\n",
    "        elif line == \"\" or line == \"\\n\" or line == \"\\r\" or \": \" not in line:\n",
    "            print(f\"+++ Empty Line found in {fp} +++\")\n",
    "            empty_line += 1\n",
    "            continue\n",
    "        else:\n",
    "            line = slicer(line.strip(), \": \")\n",
    "\n",
    "        # If the random number == 3 -> The conversation is skipped\n",
    "        # Setting the interval between 0 and 2 leads to three different trainingfiles equal in size\n",
    "        random_number = random.randint(0, 2)\n",
    "        if random_number != 3:\n",
    "            skip = random_number\n",
    "        else:\n",
    "            skipped += 1\n",
    "\n",
    "        line = line.replace(\"\\\"\", \"\").replace(\"â€™\", \"'\").replace(\"â€“\",\"-\").replace(\"â€œ\", \"\\\"\").replace(\"Â \", \" \").replace(\"â€œ\", \"\\n\").replace(\"Ã©\",\"Ã©\").replace(\"  \", \" \").replace(\"â€¦\", \"...\").replace(\"â€˜\", \"'\").replace(\"Ã©\",\"Ã©\")\n",
    "\n",
    "        # Handling Questions and Answers in the Conversation file\n",
    "        if (counter % 2) == 0 and not current == \"question\":\n",
    "            # Saving the question to append it later on\n",
    "            not_skipped_questions += 1\n",
    "            question = line\n",
    "            current = \"question\"\n",
    "        elif current == \"question\":\n",
    "            ## If a \"?\" is at the first answer, every second conversation will be skipped ##\n",
    "            if counter == 1 and \"?\" in line:\n",
    "                print(\"??? Question in the first line ???\")\n",
    "                if random.randint(0,1):\n",
    "                    print(\"??? SKIPPED ???\")\n",
    "                    break\n",
    "            ## If a \"?\" is at the first answer, every second conversation will be skipped ##\n",
    "\n",
    "            current = \"answer\"\n",
    "            answer = line\n",
    "\n",
    "            # If the answer is too long, it will be skipped\n",
    "            if len(answer) > 110:\n",
    "                skipped_too_long += 1\n",
    "                skipped += 1\n",
    "                skip = 3\n",
    "\n",
    "            # GPT3 Format ##\n",
    "            if not skip == 3:\n",
    "                not_skipped_answers += 1\n",
    "                answer_prepared = decontracted(answer)\n",
    "                random_keyword_generator = random.randint(1, 4)\n",
    "                keywords = \"\"\n",
    "\n",
    "                # Comment out one of the following alternatives. Only one can be active at a time.\n",
    "                ## Alternative RND: Random Keyword Model Chosen ##\n",
    "                if random_keyword_generator == 1:\n",
    "                    keywords = kw_keybert(answer_prepared)\n",
    "                    keywords_counter['KeyBERT'] += 1\n",
    "                elif random_keyword_generator == 2:\n",
    "                    keywords = kw_rake(answer_prepared)\n",
    "                    keywords_counter['RAKE'] += 1\n",
    "                elif random_keyword_generator == 3:\n",
    "                    keywords = kw_yake(answer_prepared)\n",
    "                    keywords_counter['YAKE'] += 1\n",
    "                else:\n",
    "                    keywords = kw_yake_detailed(answer_prepared)\n",
    "                    keywords_counter['YAKE_DETAILED'] += 1\n",
    "                ## Alternative RND: Random Keyword Model Chosen ##\n",
    "\n",
    "                ## Alternative CR: Choose the shortest keywords ##\n",
    "                # for x in range(4):\n",
    "                #     if x == 0:\n",
    "                #         keywords_attempt = kw_keybert(answer_prepared)\n",
    "                #         if len(keywords_attempt) < len(keywords) or len(keywords) == 0:\n",
    "                #             print(f\"+++ KW SHORTENED +++ (WAS: {keywords} IS NOW: {keywords_attempt}\")\n",
    "                #             keywords = keywords_attempt\n",
    "                #     elif x == 1:\n",
    "                #         keywords_attempt = kw_rake(answer_prepared)\n",
    "                #         if len(keywords_attempt) < len(keywords) or len(keywords) == 0:\n",
    "                #             print(f\"+++ KW SHORTENED +++ (WAS: {keywords} IS NOW: {keywords_attempt}\")\n",
    "                #             keywords = keywords_attempt\n",
    "                #     elif x == 2:\n",
    "                #         keywords_attempt = kw_yake(answer_prepared)\n",
    "                #         if len(keywords_attempt) < len(keywords) or len(keywords) == 0:\n",
    "                #             print(f\"+++ KW SHORTENED +++ (WAS: {keywords} IS NOW: {keywords_attempt}\")\n",
    "                #             keywords = keywords_attempt\n",
    "                #     else:\n",
    "                #         keywords_attempt = kw_yake_detailed(answer_prepared)\n",
    "                #         if len(keywords_attempt) < len(keywords) or len(keywords) == 0:\n",
    "                #             print(f\"+++ KW SHORTENED +++ (WAS: {keywords} IS NOW: {keywords_attempt}\")\n",
    "                #             keywords = keywords_attempt\n",
    "                ## Alternative CR: Choose the shortest keywords ##\n",
    "\n",
    "                # If the random chosen keyword extractor of alternative 1 did not find a keyword, the other extractors try to find one\n",
    "                if keywords == \"\":\n",
    "                    print(\"+++ Keyword Extraction -> Empty Result +++\")\n",
    "                    for x in range(4):\n",
    "                        if keywords:\n",
    "                            print(f\"+++ KW FOUND +++ (By another extraxtor)\")\n",
    "                            break\n",
    "                        if x == 0:\n",
    "                            keywords = kw_keybert(answer_prepared)\n",
    "                        elif x == 1:\n",
    "                            keywords = kw_rake(answer_prepared)\n",
    "                        elif x == 2:\n",
    "                            keywords = kw_yake(answer_prepared)\n",
    "                        else:\n",
    "                            keywords = kw_yake_detailed(answer_prepared)\n",
    "                if keywords == \"\":\n",
    "                    print(f\"+++ KW still not found +++ (No KWs found at all)\")\n",
    "                    skip = 3\n",
    "\n",
    "\n",
    "                if not skip == 3:\n",
    "                ## Check if the answer contains a negation\n",
    "                    for negated_word in list_negations:\n",
    "                        if negated_word in answer_prepared.lower():\n",
    "                            # Check if the negation is present in the keywords\n",
    "                            if negated_word not in keywords.lower():\n",
    "                                ## Check if the negation is rather in the beginning or the end and insert it in the keywords\n",
    "                                if answer_prepared.find(negated_word) < (len(answer_prepared) - len(negated_word))/2:\n",
    "                                    keywords = negated_word.replace(\" \", \"\").replace(\".\", \"\") + \" \" + keywords\n",
    "                                else:\n",
    "                                    keywords = keywords + \" \" +  negated_word.replace(\" \", \"\").replace(\".\", \"\")\n",
    "\n",
    "                    keywords_all = keyword_extractors(answer_prepared)\n",
    "\n",
    "                    filename = f\"./output_files/{timestamp}_part_{skip}_{folderpath_stripped}_training.json\"\n",
    "                    with open(filename, mode='w', encoding='utf-8') as feedsjson:\n",
    "                        ## EVERY SNIPPET AS QA PAIR ONLY WITHOUT HISTORY ##\n",
    "                        # entry = {'prompt': f\"Question: {question}\\nKeywords: {keywords}\\nAnswer:\\n\\n###\\n\\n\", 'completion': f\"{answer} END\" }\n",
    "                        # feeds.append(entry)\n",
    "                        # json.dump(feeds, feedsjson)\n",
    "                        ## EVERY SNIPPET AS QA PAIR ONLY WITHOUT HISTORY ##\n",
    "\n",
    "                        ## ALTERNATIVE WITH CACHE ARRAY ##\n",
    "                        history = \"\"\n",
    "                        for entries in cache_array:\n",
    "                            history += entries\n",
    "                        history_counter[str(len(cache_array))] += 1\n",
    "                        entry2 = {'prompt': f\"{history}Question: {question}\\nKeywords: {keywords}\\nAnswer:\\n\\n###\\n\\n\",\n",
    "                                  'completion': f\"{answer} END\"}\n",
    "                        ## ALTERNATIVE WITH CACHE ARRAY ##\n",
    "\n",
    "                        ## ALTERNATIVE W/O CACHE ARRAY ##\n",
    "                        # entry2 = {'prompt': f\"{cache}Question: {question}\\nKeywords: {keywords}\\nAnswer:\\n\\n###\\n\\n\",\n",
    "                        #           'completion': f\"{answer} END\"}\n",
    "                        ## ALTERNATIVE W/O CACHE ARRAY ##\n",
    "\n",
    "                        # Appending different arrays to have separate training files\n",
    "                        feeds['all'].append(entry2)\n",
    "                        feeds[skip].append(entry2)\n",
    "                        json.dump(feeds[skip], feedsjson)\n",
    "\n",
    "                    filename = f\"./output_files/{timestamp}_all_{folderpath_stripped}_training.json\"\n",
    "                    with open(filename, mode='w', encoding='utf-8') as feedsjson3:\n",
    "                        json.dump(feeds['all'], feedsjson3)\n",
    "\n",
    "                    ## Save keywords to compare the methods later on\n",
    "                    with open('./output_files/keyword_examples.json', mode='w', encoding='utf-8') as feedsjson2:\n",
    "                        entry2 = {'sentence': f\"{answer}\", 'keywords': keywords_all}\n",
    "                        feeds2.append(entry2)\n",
    "\n",
    "                        # For the whole conversation ##\n",
    "                        json.dump(feeds2, feedsjson2)\n",
    "            cache += f\"Question: {question}\\nAnswer: {answer}\\n\"\n",
    "            cache_array.append(f\"Question: {question}\\nAnswer: {answer}\\n\")\n",
    "        else:\n",
    "            print(\"+++ Skipped the whole file because order was mixed +++\")\n",
    "            print(\"Current: \"+ current +\" line that made it skip: Number: \" + str(counter) + line)\n",
    "            break\n",
    "        counter += 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T11:06:31.995818Z",
     "end_time": "2023-06-08T11:06:42.981407Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Printing some stats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in total: 10\n",
      "Lines in total : 142\n",
      "Empty Lines in total : 28\n",
      "Skipped too long cache : 0\n",
      "Skipped: 0\n",
      "Skipped Too long: 0\n",
      "Not Skipped Answers : 56\n",
      "Not Skipped Questions: 57\n",
      "Keywords counter: {'KeyBERT': 8, 'RAKE': 12, 'YAKE': 17, 'YAKE_DETAILED': 19}\n",
      "History counter: {'0': 19, '1': 18, '2': 8, '3': 11}\n",
      "Length of training split all: 56\n",
      "Length of training split 0: 17\n",
      "Length of training split 2: 23\n",
      "Length of training split 1: 16\n"
     ]
    }
   ],
   "source": [
    "print(\"Files in total: \" + str(files_total))\n",
    "print(\"Lines in total : \" + str(lines_total))\n",
    "print(\"Empty Lines in total : \" + str(empty_line))\n",
    "print(\"Skipped too long cache : \" + str(skipped_too_long_cache))\n",
    "print(\"Skipped: \" + str(skipped))\n",
    "print(\"Skipped Too long: \" + str(skipped_too_long))\n",
    "print(\"Not Skipped Answers : \" + str(not_skipped_answers))\n",
    "print(\"Not Skipped Questions: \" + str(not_skipped_questions))\n",
    "print(\"Keywords counter: \" + str(keywords_counter))\n",
    "print(\"History counter: \" + str(history_counter))\n",
    "for all_elements in (feeds):\n",
    "    print(f\"Length of training split {all_elements}: {len(feeds[all_elements])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T11:06:42.985589Z",
     "end_time": "2023-06-08T11:06:42.987911Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
