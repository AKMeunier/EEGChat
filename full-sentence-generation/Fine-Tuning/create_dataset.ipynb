{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T11:06:31.001734Z",
     "start_time": "2023-06-08T11:06:30.999933Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from keybert import KeyBERT\n",
    "from multi_rake import Rake\n",
    "import yake\n",
    "import os\n",
    "import collections\n",
    "import json\n",
    "# import num2words\n",
    "import re\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T11:06:31.963561Z",
     "start_time": "2023-06-08T11:06:31.002842Z"
    }
   },
   "outputs": [],
   "source": [
    "dt = datetime.datetime.now()\n",
    "timestamp = dt.strftime('%Y_%m_%d_%H:%M:%S')[:-3]\n",
    "\n",
    "kw_model = KeyBERT(model='all-mpnet-base-v2')\n",
    "\n",
    "\n",
    "def kw_yake(text):\n",
    "    # kw_extractor = yake.KeywordExtractor()\n",
    "    language = \"en\"\n",
    "    max_ngram_size = 1\n",
    "    deduplication_threshold = 0.9\n",
    "    numOfKeywords = 10\n",
    "    custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold,\n",
    "                                                top=numOfKeywords, features=None)\n",
    "    keywords = custom_kw_extractor.extract_keywords(text)\n",
    "    keywords_str = \"\"\n",
    "    for index, keyword in enumerate(keywords):\n",
    "        if index == len(keywords) - 1:\n",
    "            keywords_str += f\"{keyword[0]}\"\n",
    "        else:\n",
    "            keywords_str += f\"{keyword[0]} \"\n",
    "    return keywords_str\n",
    "\n",
    "\n",
    "def kw_yake_detailed(text):\n",
    "    language = \"en\"\n",
    "    max_ngram_size = 5\n",
    "    deduplication_threshold = 0.0\n",
    "    numOfKeywords = 10\n",
    "    custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold,\n",
    "                                                top=numOfKeywords, features=None)\n",
    "    keywords = custom_kw_extractor.extract_keywords(text)\n",
    "    keywords_str = \"\"\n",
    "    for index, keyword in enumerate(keywords):\n",
    "        if index == len(keywords) - 1:\n",
    "            keywords_str += f\"{keyword[0]}\"\n",
    "        else:\n",
    "            keywords_str += f\"{keyword[0]} \"\n",
    "    return keywords_str\n",
    "\n",
    "\n",
    "def kw_rake(text):\n",
    "    rake = Rake()\n",
    "    keywords = rake.apply(text)\n",
    "    keywords_str = \"\"\n",
    "    for index, keyword in enumerate(keywords):\n",
    "        if index == len(keywords) - 1:\n",
    "            keywords_str += f\"{keyword[0]}\"\n",
    "        else:\n",
    "            keywords_str += f\"{keyword[0]} \"\n",
    "    return (keywords_str)\n",
    "\n",
    "\n",
    "def kw_keybert(text):\n",
    "    keywords = kw_model.extract_keywords(\n",
    "        text,\n",
    "        keyphrase_ngram_range=(1, 7),\n",
    "        stop_words='english',\n",
    "        highlight=False,\n",
    "        top_n=1)\n",
    "    keywords_list = list(dict(keywords).keys())\n",
    "    if not keywords_list:\n",
    "        return \"\"\n",
    "    return (keywords_list[0])\n",
    "\n",
    "\n",
    "def keyword_extractors(text):\n",
    "    keywords = ({\n",
    "        \"KeyBERT\": kw_keybert(text),\n",
    "        \"RAKE\": kw_rake(text),\n",
    "        \"YAKE\": kw_yake(text),\n",
    "        \"YAKE (Detailed)\": kw_yake_detailed(text),\n",
    "    })\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decontraction Function and slicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T11:06:31.969626Z",
     "start_time": "2023-06-08T11:06:31.968028Z"
    }
   },
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    phrase = re.sub(r\"Won\\'t\", \"Will not\", phrase)\n",
    "    phrase = re.sub(r\"Can\\'t\", \"Can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "list_negations = [\n",
    "    \" not \",\n",
    "    \" not.\",\n",
    "    \" no \",\n",
    "    \" no.\"\n",
    "]\n",
    "\n",
    "def slicer(my_str, sub):\n",
    "    index = my_str.find(sub)\n",
    "    if index != -1:\n",
    "        return my_str[index + len(sub):]\n",
    "    else:\n",
    "        raise Exception('Sub string not found!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folder Paths and reading the raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T11:06:31.977814Z",
     "start_time": "2023-06-08T11:06:31.972678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./txt_conversations/1. Visiting a Travel Agent.txt\n",
      "./txt_conversations/1. I Feel Like Chinese.txt\n",
      "./txt_conversations/1. Making Plans for the Weekend.txt\n",
      "./txt_conversations/1. I Go to College.txt\n",
      "./txt_conversations/1. Looking for a Job.txt\n",
      "./txt_conversations/1. Too Much Crime.txt\n",
      "./txt_conversations/1. Which Bus to Take (1).txt\n",
      "./txt_conversations/1. I Live in Pasadena.txt\n",
      "./txt_conversations/1. What Will People Think.txt\n",
      "./txt_conversations/1. Unemployment Insurance.txt\n"
     ]
    }
   ],
   "source": [
    "folderpath = r\"./txt_conversations\"  # make sure to put the 'r' in front\n",
    "folderpath_stripped = folderpath.replace(\"./\",\"\")\n",
    "\n",
    "filepaths = [os.path.join(folderpath, name) for name in os.listdir(folderpath)]\n",
    "all_files = []\n",
    "\n",
    "for path in filepaths:\n",
    "    print(path)\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            file = f.readlines()\n",
    "            all_files.append(file)\n",
    "    except:\n",
    "        print(\"EXCEPTION\" + path)\n",
    "        continue\n",
    "\n",
    "files_as_text = []\n",
    "for elements in all_files:\n",
    "    text = \"\"\n",
    "    for lines in elements:\n",
    "        try:\n",
    "            text += lines\n",
    "        except:\n",
    "            print(\"Exception in all files\")\n",
    "            continue\n",
    "    files_as_text.append(text)\n",
    "\n",
    "with open('./output_files/all_text.json', mode='w', encoding='utf-8') as feedsjson2:\n",
    "    json.dump(all_files, feedsjson2)\n",
    "\n",
    "with open('./output_files/all_text_array.json', mode='w', encoding='utf-8') as feedsjson3:\n",
    "    json.dump(files_as_text, feedsjson3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T11:06:31.982396Z",
     "start_time": "2023-06-08T11:06:31.980799Z"
    }
   },
   "outputs": [],
   "source": [
    "feeds = collections.defaultdict(list)\n",
    "feeds2 = []\n",
    "current = \"\"\n",
    "files_total = 0\n",
    "lines_total = 0\n",
    "skipped = 0\n",
    "not_skipped_answers = 0\n",
    "skipped_too_long = 0\n",
    "skipped_too_long_cache = 0\n",
    "not_skipped_questions = 0\n",
    "empty_line = 0\n",
    "keywords_counter = ({\n",
    "        \"KeyBERT\": 0,\n",
    "        \"RAKE\": 0,\n",
    "        \"YAKE\": 0,\n",
    "        'YAKE_DETAILED': 0\n",
    "    })\n",
    "\n",
    "history_counter = ({\n",
    "        \"0\": 0,\n",
    "        \"1\": 0,\n",
    "        \"2\": 0,\n",
    "        '3': 0\n",
    "    })\n",
    "\n",
    "length = len(all_files)\n",
    "counter_1 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating through all files and create the dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T11:06:42.981407Z",
     "start_time": "2023-06-08T11:06:31.995818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________## 10.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', 'A: Thank you for coming to our travel agency. How can I help you?\\n', 'B: I would like to book a trip to Disney World for my family.\\n', 'A: Your family will have much fun. When do you want to go?\\n', 'B: We want to go during the summer when the kids have off from school.\\n', \"A: I suggest early June because it won't rain too much and the park isn't as crowded as later in the season.\\n\", \"B: Great! let's do the second week in June.\\n\", 'A: How many adults and how many children will be travelling?\\n', 'B: There are two adults and two children.\\n', 'A: Do you have an airline preference?\\n', 'B: No. I have no preference as long as the flight is non-stop.\\n', 'A: Do you want a budget hotel or a luxury hotel?\\n', 'B: Can you book something in between?\\n', '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', 'A: Thank you for coming to our travel agency. How can I help you?\\n', 'B: I would like to book a trip to Disney World for my family.\\n', 'A: Your family will have much fun. When do you want to go?\\n', 'B: We want to go during the summer when the kids have off from school.\\n', \"A: I suggest early June because it won't rain too much and the park isn't as crowded as later in the season.\\n\", \"B: Great! let's do the second week in June.\\n\", 'A: How many adults and how many children will be travelling?\\n', 'B: There are two adults and two children.\\n', 'A: Do you have an airline preference?\\n', 'B: No. I have no preference as long as the flight is non-stop.\\n', 'A: Do you want a budget hotel or a luxury hotel?\\n', 'B: Can you book something in between?\\n', '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', 'A: Thank you for coming to our travel agency. How can I help you?\\n', 'B: I would like to book a trip to Disney World for my family.\\n', 'A: Your family will have much fun. When do you want to go?\\n', 'B: We want to go during the summer when the kids have off from school.\\n', \"A: I suggest early June because it won't rain too much and the park isn't as crowded as later in the season.\\n\", \"B: Great! let's do the second week in June.\\n\", 'A: How many adults and how many children will be travelling?\\n', 'B: There are two adults and two children.\\n', 'A: Do you have an airline preference?\\n', 'B: No. I have no preference as long as the flight is non-stop.\\n', 'A: Do you want a budget hotel or a luxury hotel?\\n', 'B: Can you book something in between?\\n', '\\n', '\\n'] +++\n",
      "______________## 20.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', \"A: Let's go out to eat.\\n\", 'B: That sounds like fun.\\n', 'A: Where do you want to go?\\n', 'B: Let me think a minute.\\n', 'A: I feel like Chinese.\\n', 'B: That sounds delicious.\\n', 'A: I know a good Chinese restaurant.\\n', 'B: How far away is it?\\n', \"A: It's only 10 minutes from here.\\n\", 'B: Do we need reservations?\\n', 'A: Oh, no. We can walk right in.\\n', \"B: Let's go now. I'm hungry!\\n\", '\\n', '\\n'] +++\n",
      "+++ Keyword Extraction -> Empty Result +++\n",
      "+++ KW FOUND +++ (By another extraxtor)\n",
      "+++ Empty Line found in ['\\n', \"A: Let's go out to eat.\\n\", 'B: That sounds like fun.\\n', 'A: Where do you want to go?\\n', 'B: Let me think a minute.\\n', 'A: I feel like Chinese.\\n', 'B: That sounds delicious.\\n', 'A: I know a good Chinese restaurant.\\n', 'B: How far away is it?\\n', \"A: It's only 10 minutes from here.\\n\", 'B: Do we need reservations?\\n', 'A: Oh, no. We can walk right in.\\n', \"B: Let's go now. I'm hungry!\\n\", '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', \"A: Let's go out to eat.\\n\", 'B: That sounds like fun.\\n', 'A: Where do you want to go?\\n', 'B: Let me think a minute.\\n', 'A: I feel like Chinese.\\n', 'B: That sounds delicious.\\n', 'A: I know a good Chinese restaurant.\\n', 'B: How far away is it?\\n', \"A: It's only 10 minutes from here.\\n\", 'B: Do we need reservations?\\n', 'A: Oh, no. We can walk right in.\\n', \"B: Let's go now. I'm hungry!\\n\", '\\n', '\\n'] +++\n",
      "______________## 30.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', 'A: What are you going to do this weekend?\\n', \"B: I haven't made any solid plans yet. Why do you ask?\\n\", \"A: There's this event at a bookstore downtown I was thinking of checking out.\\n\", 'B: That sounds really interesting.\\n', \"A: Yeah, and even if it's not, we can leave and grab a bite.\\n\", 'B: There are so many nice new places that have opened up downtown.\\n', 'A: I know, and have wanted to try them all.\\n', 'B: So our meeting time is Saturday at three.\\n', \"A: I'll meet you at the bookstore.\\n\", \"B: It's the bookstore on Spring Street.\\n\", 'A: We can grab some food and drinks after.\\n', 'B: An early dinner sounds great.\\n', '\\n', '\\n'] +++\n",
      "??? Question in the first line ???\n",
      "+++ Empty Line found in ['\\n', 'A: What are you going to do this weekend?\\n', \"B: I haven't made any solid plans yet. Why do you ask?\\n\", \"A: There's this event at a bookstore downtown I was thinking of checking out.\\n\", 'B: That sounds really interesting.\\n', \"A: Yeah, and even if it's not, we can leave and grab a bite.\\n\", 'B: There are so many nice new places that have opened up downtown.\\n', 'A: I know, and have wanted to try them all.\\n', 'B: So our meeting time is Saturday at three.\\n', \"A: I'll meet you at the bookstore.\\n\", \"B: It's the bookstore on Spring Street.\\n\", 'A: We can grab some food and drinks after.\\n', 'B: An early dinner sounds great.\\n', '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', 'A: What are you going to do this weekend?\\n', \"B: I haven't made any solid plans yet. Why do you ask?\\n\", \"A: There's this event at a bookstore downtown I was thinking of checking out.\\n\", 'B: That sounds really interesting.\\n', \"A: Yeah, and even if it's not, we can leave and grab a bite.\\n\", 'B: There are so many nice new places that have opened up downtown.\\n', 'A: I know, and have wanted to try them all.\\n', 'B: So our meeting time is Saturday at three.\\n', \"A: I'll meet you at the bookstore.\\n\", \"B: It's the bookstore on Spring Street.\\n\", 'A: We can grab some food and drinks after.\\n', 'B: An early dinner sounds great.\\n', '\\n', '\\n'] +++\n",
      "______________## 40.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', 'A: Do you go to college?\\n', 'B: Yes, I do.\\n', 'A: What college do you go to?\\n', 'B: I go to Pasadena City College.\\n', 'A: Do you like it?\\n', 'B: Oh, yes, I really like it.\\n', 'A: Why do you like it?\\n', 'B: Because it has great teachers.\\n', 'A: What else?\\n', 'B: I like all my classmates, too.\\n', 'A: Anything else?\\n', \"B: Yes. It's not expensive!\\n\", '\\n', '\\n'] +++\n",
      "+++ Keyword Extraction -> Empty Result +++\n",
      "+++ KW FOUND +++ (By another extraxtor)\n",
      "+++ Empty Line found in ['\\n', 'A: Do you go to college?\\n', 'B: Yes, I do.\\n', 'A: What college do you go to?\\n', 'B: I go to Pasadena City College.\\n', 'A: Do you like it?\\n', 'B: Oh, yes, I really like it.\\n', 'A: Why do you like it?\\n', 'B: Because it has great teachers.\\n', 'A: What else?\\n', 'B: I like all my classmates, too.\\n', 'A: Anything else?\\n', \"B: Yes. It's not expensive!\\n\", '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', 'A: Do you go to college?\\n', 'B: Yes, I do.\\n', 'A: What college do you go to?\\n', 'B: I go to Pasadena City College.\\n', 'A: Do you like it?\\n', 'B: Oh, yes, I really like it.\\n', 'A: Why do you like it?\\n', 'B: Because it has great teachers.\\n', 'A: What else?\\n', 'B: I like all my classmates, too.\\n', 'A: Anything else?\\n', \"B: Yes. It's not expensive!\\n\", '\\n', '\\n'] +++\n",
      "______________## 50.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', \"A: Hey Dennis, this is Ron. How's it going?\\n\", \"B: Hi, Ron. I'm looking for a summer job. I was hoping you could help me.\\n\", 'A: Okay, how can I help you?\\n', 'B: Well, I was wondering if you could hook me up at the place you work.\\n', \"A: No problem. I don't know if they're hiring, but I'll find out.\\n\", \"B: Aw man, you're the bomb!\\n\", 'A: What kind of job you are interested in doing?\\n', 'B: Anything you think that I can do will be fine.\\n', \"A: I'll talk to my boss in the morning and get back to you.\\n\", 'B: Thanks, man. A friend in need is a friend indeed.\\n', 'A: Anything else you need me to do?\\n', \"B: No. I'm waiting to hear from you.\\n\", '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', \"A: Hey Dennis, this is Ron. How's it going?\\n\", \"B: Hi, Ron. I'm looking for a summer job. I was hoping you could help me.\\n\", 'A: Okay, how can I help you?\\n', 'B: Well, I was wondering if you could hook me up at the place you work.\\n', \"A: No problem. I don't know if they're hiring, but I'll find out.\\n\", \"B: Aw man, you're the bomb!\\n\", 'A: What kind of job you are interested in doing?\\n', 'B: Anything you think that I can do will be fine.\\n', \"A: I'll talk to my boss in the morning and get back to you.\\n\", 'B: Thanks, man. A friend in need is a friend indeed.\\n', 'A: Anything else you need me to do?\\n', \"B: No. I'm waiting to hear from you.\\n\", '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', \"A: Hey Dennis, this is Ron. How's it going?\\n\", \"B: Hi, Ron. I'm looking for a summer job. I was hoping you could help me.\\n\", 'A: Okay, how can I help you?\\n', 'B: Well, I was wondering if you could hook me up at the place you work.\\n', \"A: No problem. I don't know if they're hiring, but I'll find out.\\n\", \"B: Aw man, you're the bomb!\\n\", 'A: What kind of job you are interested in doing?\\n', 'B: Anything you think that I can do will be fine.\\n', \"A: I'll talk to my boss in the morning and get back to you.\\n\", 'B: Thanks, man. A friend in need is a friend indeed.\\n', 'A: Anything else you need me to do?\\n', \"B: No. I'm waiting to hear from you.\\n\", '\\n', '\\n'] +++\n",
      "______________## 60.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', 'A: Why is there so much crime?\\n', \"B: Because parents don't teach their kids right from wrong.\\n\", 'A: Is that it?\\n', \"B: Also, there aren't enough police.\\n\", 'A: But there are a lot of police.\\n', \"B: There's only one police officer per 100 criminals.\\n\", \"A: Can't we hire more police?\\n\", 'B: No. It costs too much money.\\n', \"A: Doesn't crime cost more than police?\\n\", 'B: Yes, it does.\\n', 'A: So it would be cheaper to hire more police?\\n', 'B: Yes, it would.\\n', '\\n', '\\n'] +++\n",
      "+++ Keyword Extraction -> Empty Result +++\n",
      "+++ KW FOUND +++ (By another extraxtor)\n",
      "+++ Keyword Extraction -> Empty Result +++\n",
      "+++ KW FOUND +++ (By another extraxtor)\n",
      "+++ Empty Line found in ['\\n', 'A: Why is there so much crime?\\n', \"B: Because parents don't teach their kids right from wrong.\\n\", 'A: Is that it?\\n', \"B: Also, there aren't enough police.\\n\", 'A: But there are a lot of police.\\n', \"B: There's only one police officer per 100 criminals.\\n\", \"A: Can't we hire more police?\\n\", 'B: No. It costs too much money.\\n', \"A: Doesn't crime cost more than police?\\n\", 'B: Yes, it does.\\n', 'A: So it would be cheaper to hire more police?\\n', 'B: Yes, it would.\\n', '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', 'A: Why is there so much crime?\\n', \"B: Because parents don't teach their kids right from wrong.\\n\", 'A: Is that it?\\n', \"B: Also, there aren't enough police.\\n\", 'A: But there are a lot of police.\\n', \"B: There's only one police officer per 100 criminals.\\n\", \"A: Can't we hire more police?\\n\", 'B: No. It costs too much money.\\n', \"A: Doesn't crime cost more than police?\\n\", 'B: Yes, it does.\\n', 'A: So it would be cheaper to hire more police?\\n', 'B: Yes, it would.\\n', '\\n', '\\n'] +++\n",
      "______________## 70.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', 'A: You seem a little lost.\\n', 'B: I actually am lost. How could you tell?\\n', 'A: The look on your face said it all.\\n', 'B: Maybe you could help me.\\n', \"A: I'd be happy to help.\\n\", \"B: I'm not sure what bus I'm supposed to take.\\n\", \"A: What's your destination?\\n\", \"B: I'm heading to Westwood.\\n\", \"A: I've been there several times by bus.\\n\", 'B: You have? What bus did you take?\\n', 'A: The Line 720 takes you directly there.\\n', 'B: Where is the stop for that bus?\\n', 'A: Right at the corner over there.\\n', 'B: Thank you very much.\\n', '\\n', '\\n'] +++\n",
      "??? Question in the first line ???\n",
      "+++ Keyword Extraction -> Empty Result +++\n",
      "+++ KW FOUND +++ (By another extraxtor)\n",
      "+++ Empty Line found in ['\\n', 'A: You seem a little lost.\\n', 'B: I actually am lost. How could you tell?\\n', 'A: The look on your face said it all.\\n', 'B: Maybe you could help me.\\n', \"A: I'd be happy to help.\\n\", \"B: I'm not sure what bus I'm supposed to take.\\n\", \"A: What's your destination?\\n\", \"B: I'm heading to Westwood.\\n\", \"A: I've been there several times by bus.\\n\", 'B: You have? What bus did you take?\\n', 'A: The Line 720 takes you directly there.\\n', 'B: Where is the stop for that bus?\\n', 'A: Right at the corner over there.\\n', 'B: Thank you very much.\\n', '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', 'A: You seem a little lost.\\n', 'B: I actually am lost. How could you tell?\\n', 'A: The look on your face said it all.\\n', 'B: Maybe you could help me.\\n', \"A: I'd be happy to help.\\n\", \"B: I'm not sure what bus I'm supposed to take.\\n\", \"A: What's your destination?\\n\", \"B: I'm heading to Westwood.\\n\", \"A: I've been there several times by bus.\\n\", 'B: You have? What bus did you take?\\n', 'A: The Line 720 takes you directly there.\\n', 'B: Where is the stop for that bus?\\n', 'A: Right at the corner over there.\\n', 'B: Thank you very much.\\n', '\\n', '\\n'] +++\n",
      "______________## 80.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', 'A: Where do you live?\\n', 'B: I live in Pasadena.\\n', 'A: Where is Pasadena?\\n', \"B: It's in California.\\n\", 'A: Is it in northern California?\\n', \"B: No. It's in southern California.\\n\", 'A: Is Pasadena a big city?\\n', \"B: It's pretty big.\\n\", 'A: How big is \"pretty big\"?\\n', 'B: It has about 140,000 people.\\n', 'A: How big is Los Angeles?\\n', 'B: It has about 3 million people.\\n', '\\n', '\\n'] +++\n",
      "+++ Keyword Extraction -> Empty Result +++\n",
      "+++ KW FOUND +++ (By another extraxtor)\n",
      "+++ Empty Line found in ['\\n', 'A: Where do you live?\\n', 'B: I live in Pasadena.\\n', 'A: Where is Pasadena?\\n', \"B: It's in California.\\n\", 'A: Is it in northern California?\\n', \"B: No. It's in southern California.\\n\", 'A: Is Pasadena a big city?\\n', \"B: It's pretty big.\\n\", 'A: How big is \"pretty big\"?\\n', 'B: It has about 140,000 people.\\n', 'A: How big is Los Angeles?\\n', 'B: It has about 3 million people.\\n', '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', 'A: Where do you live?\\n', 'B: I live in Pasadena.\\n', 'A: Where is Pasadena?\\n', \"B: It's in California.\\n\", 'A: Is it in northern California?\\n', \"B: No. It's in southern California.\\n\", 'A: Is Pasadena a big city?\\n', \"B: It's pretty big.\\n\", 'A: How big is \"pretty big\"?\\n', 'B: It has about 140,000 people.\\n', 'A: How big is Los Angeles?\\n', 'B: It has about 3 million people.\\n', '\\n', '\\n'] +++\n",
      "______________## 90.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', \"A: I don't like riding the bus.\\n\", 'B: Why not?\\n', 'A: The seats and windows are dirty.\\n', \"B: Don't they clean the bus every night?\\n\", 'A: I think they do.\\n', 'B: You should bring some wipes with you.\\n', \"A: That's a good idea.\\n\", 'B: Then you can wipe your seat and window.\\n', \"A: People will think I'm strange.\\n\", 'B: Who cares? Everyone is strange.\\n', \"A: That's for sure.\\n\", \"B: Don't worry about what people think.\\n\", '\\n', '\\n'] +++\n",
      "??? Question in the first line ???\n",
      "??? SKIPPED ???\n",
      "______________## 100.0 % ##______________\n",
      "+++ Empty Line found in ['\\n', 'A: Hey Diana, why so glum?\\n', 'B: Aw Bobby, I just lost my job.\\n', 'A: Oh, no. What happened?\\n', 'B: The company is relocating to another state.\\n', \"A: That's tough, Diana. What are you going to do now?\\n\", \"B: I'm looking for a new job. I need to pay my bills.\\n\", 'A: Are you filing for unemployment benefits?\\n', \"B: I don't think I'm eligible. I only worked there three months.\\n\", \"A: Sure, you're eligible. You worked long enough.\\n\", \"B: I didn't know that.\\n\", 'A: I think you only have to work for two weeks to be eligible.\\n', \"B: That's great. I hope I can get it.\\n\", \"A: You'll never know untill you try.\\n\", \"B: Thanks, Bobby. You're a good friend.\\n\", '\\n', '\\n'] +++\n",
      "+++ Keyword Extraction -> Empty Result +++\n",
      "+++ KW FOUND +++ (By another extraxtor)\n",
      "+++ Empty Line found in ['\\n', 'A: Hey Diana, why so glum?\\n', 'B: Aw Bobby, I just lost my job.\\n', 'A: Oh, no. What happened?\\n', 'B: The company is relocating to another state.\\n', \"A: That's tough, Diana. What are you going to do now?\\n\", \"B: I'm looking for a new job. I need to pay my bills.\\n\", 'A: Are you filing for unemployment benefits?\\n', \"B: I don't think I'm eligible. I only worked there three months.\\n\", \"A: Sure, you're eligible. You worked long enough.\\n\", \"B: I didn't know that.\\n\", 'A: I think you only have to work for two weeks to be eligible.\\n', \"B: That's great. I hope I can get it.\\n\", \"A: You'll never know untill you try.\\n\", \"B: Thanks, Bobby. You're a good friend.\\n\", '\\n', '\\n'] +++\n",
      "+++ Empty Line found in ['\\n', 'A: Hey Diana, why so glum?\\n', 'B: Aw Bobby, I just lost my job.\\n', 'A: Oh, no. What happened?\\n', 'B: The company is relocating to another state.\\n', \"A: That's tough, Diana. What are you going to do now?\\n\", \"B: I'm looking for a new job. I need to pay my bills.\\n\", 'A: Are you filing for unemployment benefits?\\n', \"B: I don't think I'm eligible. I only worked there three months.\\n\", \"A: Sure, you're eligible. You worked long enough.\\n\", \"B: I didn't know that.\\n\", 'A: I think you only have to work for two weeks to be eligible.\\n', \"B: That's great. I hope I can get it.\\n\", \"A: You'll never know untill you try.\\n\", \"B: Thanks, Bobby. You're a good friend.\\n\", '\\n', '\\n'] +++\n"
     ]
    }
   ],
   "source": [
    "for fp in all_files:\n",
    "    counter_1 += 1\n",
    "    print(f\"______________## {(counter_1/length)*100} % ##______________\")\n",
    "    http_in_file = False\n",
    "    for lines in fp:\n",
    "        if \"http\" in lines:\n",
    "            print(\"+++ HTTP IN LINE +++\")\n",
    "            http_in_file = True\n",
    "    files_total += 1\n",
    "    current = \"\"\n",
    "    lines = []\n",
    "    counter = 0\n",
    "    cache = \"\"\n",
    "    cache_happy_transformers = \"\"\n",
    "    cache_array = []\n",
    "    http_here = False\n",
    "\n",
    "    for i, line in enumerate(fp):\n",
    "        ## ALTERNATIVE 1 ##\n",
    "        # For all conversations where the history is longer than 900 chars, the conversation is skipped\n",
    "        # if len(cache) > 900:\n",
    "        #     skipped_too_long_cache +=1\n",
    "        #     continue\n",
    "        ## ALTERNATIVE 1 ##\n",
    "\n",
    "\n",
    "        ## ALTERNATIVE 2 ##\n",
    "        # It is randomly chosen, how long the appended history in a conversation is\n",
    "        # It is never longer than 3 QA-Pairs\n",
    "        if len(cache_array) == 1:\n",
    "            pop_random = random.randint(1, 5)\n",
    "            if pop_random == 1:\n",
    "                cache_array.clear()\n",
    "\n",
    "        if len(cache_array) == 2:\n",
    "            pop_random = random.randint(0, 5)\n",
    "            if pop_random == 1:\n",
    "                cache_array.pop(0)\n",
    "            elif pop_random == 2:\n",
    "                cache_array.pop(0)\n",
    "                cache_array.pop(0)\n",
    "            elif pop_random == 3:\n",
    "                cache_array.clear()\n",
    "\n",
    "        if len(cache_array) > 3:\n",
    "            pop_random = random.randint(1, 3)\n",
    "            if pop_random == 1:\n",
    "                cache_array.pop(0)\n",
    "            elif pop_random == 2:\n",
    "                cache_array.pop(0)\n",
    "                cache_array.pop(0)\n",
    "            elif pop_random == 3:\n",
    "                cache_array.clear()\n",
    "        ## ALTERNATIVE 2 ##\n",
    "\n",
    "        lines_total += 1\n",
    "\n",
    "        # Sometimes there are HTTP links or empty lines in the conversations -> Those are skipped\n",
    "        if http_in_file:\n",
    "            if line == \"\" or line == \"\\n\" or line == \"\\r\" or http_here is False:\n",
    "                if \"http\" in line:\n",
    "                    http_here = True\n",
    "                print(f\"+++ Empty Line found in HTTP  {fp} +++\")\n",
    "                empty_line += 1\n",
    "                continue\n",
    "        elif line == \"\" or line == \"\\n\" or line == \"\\r\" or \": \" not in line:\n",
    "            print(f\"+++ Empty Line found in {fp} +++\")\n",
    "            empty_line += 1\n",
    "            continue\n",
    "        else:\n",
    "            line = slicer(line.strip(), \": \")\n",
    "\n",
    "        # If the random number == 3 -> The conversation is skipped\n",
    "        # Setting the interval between 0 and 2 leads to three different trainingfiles equal in size\n",
    "        random_number = random.randint(0, 2)\n",
    "        if random_number != 3:\n",
    "            skip = random_number\n",
    "        else:\n",
    "            skipped += 1\n",
    "\n",
    "        line = line.replace(\"\\\"\", \"\").replace(\"’\", \"'\").replace(\"–\",\"-\").replace(\"“\", \"\\\"\").replace(\" \", \" \").replace(\"“\", \"\\n\").replace(\"é\",\"é\").replace(\"  \", \" \").replace(\"…\", \"...\").replace(\"‘\", \"'\").replace(\"é\",\"é\")\n",
    "\n",
    "        # Handling Questions and Answers in the Conversation file\n",
    "        if (counter % 2) == 0 and not current == \"question\":\n",
    "            # Saving the question to append it later on\n",
    "            not_skipped_questions += 1\n",
    "            question = line\n",
    "            current = \"question\"\n",
    "        elif current == \"question\":\n",
    "            ## If a \"?\" is at the first answer, every second conversation will be skipped ##\n",
    "            if counter == 1 and \"?\" in line:\n",
    "                print(\"??? Question in the first line ???\")\n",
    "                if random.randint(0,1):\n",
    "                    print(\"??? SKIPPED ???\")\n",
    "                    break\n",
    "            ## If a \"?\" is at the first answer, every second conversation will be skipped ##\n",
    "\n",
    "            current = \"answer\"\n",
    "            answer = line\n",
    "\n",
    "            # If the answer is too long, it will be skipped\n",
    "            if len(answer) > 110:\n",
    "                skipped_too_long += 1\n",
    "                skipped += 1\n",
    "                skip = 3\n",
    "\n",
    "            # GPT3 Format ##\n",
    "            if not skip == 3:\n",
    "                not_skipped_answers += 1\n",
    "                answer_prepared = decontracted(answer)\n",
    "                random_keyword_generator = random.randint(1, 4)\n",
    "                keywords = \"\"\n",
    "\n",
    "                # Comment out one of the following alternatives. Only one can be active at a time.\n",
    "                ## Alternative RND: Random Keyword Model Chosen ##\n",
    "                if random_keyword_generator == 1:\n",
    "                    keywords = kw_keybert(answer_prepared)\n",
    "                    keywords_counter['KeyBERT'] += 1\n",
    "                elif random_keyword_generator == 2:\n",
    "                    keywords = kw_rake(answer_prepared)\n",
    "                    keywords_counter['RAKE'] += 1\n",
    "                elif random_keyword_generator == 3:\n",
    "                    keywords = kw_yake(answer_prepared)\n",
    "                    keywords_counter['YAKE'] += 1\n",
    "                else:\n",
    "                    keywords = kw_yake_detailed(answer_prepared)\n",
    "                    keywords_counter['YAKE_DETAILED'] += 1\n",
    "                ## Alternative RND: Random Keyword Model Chosen ##\n",
    "\n",
    "                ## Alternative CR: Choose the shortest keywords ##\n",
    "                # for x in range(4):\n",
    "                #     if x == 0:\n",
    "                #         keywords_attempt = kw_keybert(answer_prepared)\n",
    "                #         if len(keywords_attempt) < len(keywords) or len(keywords) == 0:\n",
    "                #             print(f\"+++ KW SHORTENED +++ (WAS: {keywords} IS NOW: {keywords_attempt}\")\n",
    "                #             keywords = keywords_attempt\n",
    "                #     elif x == 1:\n",
    "                #         keywords_attempt = kw_rake(answer_prepared)\n",
    "                #         if len(keywords_attempt) < len(keywords) or len(keywords) == 0:\n",
    "                #             print(f\"+++ KW SHORTENED +++ (WAS: {keywords} IS NOW: {keywords_attempt}\")\n",
    "                #             keywords = keywords_attempt\n",
    "                #     elif x == 2:\n",
    "                #         keywords_attempt = kw_yake(answer_prepared)\n",
    "                #         if len(keywords_attempt) < len(keywords) or len(keywords) == 0:\n",
    "                #             print(f\"+++ KW SHORTENED +++ (WAS: {keywords} IS NOW: {keywords_attempt}\")\n",
    "                #             keywords = keywords_attempt\n",
    "                #     else:\n",
    "                #         keywords_attempt = kw_yake_detailed(answer_prepared)\n",
    "                #         if len(keywords_attempt) < len(keywords) or len(keywords) == 0:\n",
    "                #             print(f\"+++ KW SHORTENED +++ (WAS: {keywords} IS NOW: {keywords_attempt}\")\n",
    "                #             keywords = keywords_attempt\n",
    "                ## Alternative CR: Choose the shortest keywords ##\n",
    "\n",
    "                # If the random chosen keyword extractor of alternative 1 did not find a keyword, the other extractors try to find one\n",
    "                if keywords == \"\":\n",
    "                    print(\"+++ Keyword Extraction -> Empty Result +++\")\n",
    "                    for x in range(4):\n",
    "                        if keywords:\n",
    "                            print(f\"+++ KW FOUND +++ (By another extraxtor)\")\n",
    "                            break\n",
    "                        if x == 0:\n",
    "                            keywords = kw_keybert(answer_prepared)\n",
    "                        elif x == 1:\n",
    "                            keywords = kw_rake(answer_prepared)\n",
    "                        elif x == 2:\n",
    "                            keywords = kw_yake(answer_prepared)\n",
    "                        else:\n",
    "                            keywords = kw_yake_detailed(answer_prepared)\n",
    "                if keywords == \"\":\n",
    "                    print(f\"+++ KW still not found +++ (No KWs found at all)\")\n",
    "                    skip = 3\n",
    "\n",
    "\n",
    "                if not skip == 3:\n",
    "                ## Check if the answer contains a negation\n",
    "                    for negated_word in list_negations:\n",
    "                        if negated_word in answer_prepared.lower():\n",
    "                            # Check if the negation is present in the keywords\n",
    "                            if negated_word not in keywords.lower():\n",
    "                                ## Check if the negation is rather in the beginning or the end and insert it in the keywords\n",
    "                                if answer_prepared.find(negated_word) < (len(answer_prepared) - len(negated_word))/2:\n",
    "                                    keywords = negated_word.replace(\" \", \"\").replace(\".\", \"\") + \" \" + keywords\n",
    "                                else:\n",
    "                                    keywords = keywords + \" \" +  negated_word.replace(\" \", \"\").replace(\".\", \"\")\n",
    "\n",
    "                    keywords_all = keyword_extractors(answer_prepared)\n",
    "\n",
    "                    filename = f\"./output_files/{timestamp}_part_{skip}_{folderpath_stripped}_training.json\"\n",
    "                    with open(filename, mode='w', encoding='utf-8') as feedsjson:\n",
    "                        ## EVERY SNIPPET AS QA PAIR ONLY WITHOUT HISTORY ##\n",
    "                        # entry = {'prompt': f\"Question: {question}\\nKeywords: {keywords}\\nAnswer:\\n\\n###\\n\\n\", 'completion': f\"{answer} END\" }\n",
    "                        # feeds.append(entry)\n",
    "                        # json.dump(feeds, feedsjson)\n",
    "                        ## EVERY SNIPPET AS QA PAIR ONLY WITHOUT HISTORY ##\n",
    "\n",
    "                        ## ALTERNATIVE WITH CACHE ARRAY ##\n",
    "                        history = \"\"\n",
    "                        for entries in cache_array:\n",
    "                            history += entries\n",
    "                        history_counter[str(len(cache_array))] += 1\n",
    "                        entry2 = {'prompt': f\"{history}Question: {question}\\nKeywords: {keywords}\\nAnswer:\\n\\n###\\n\\n\",\n",
    "                                  'completion': f\"{answer} END\"}\n",
    "                        ## ALTERNATIVE WITH CACHE ARRAY ##\n",
    "\n",
    "                        ## ALTERNATIVE W/O CACHE ARRAY ##\n",
    "                        # entry2 = {'prompt': f\"{cache}Question: {question}\\nKeywords: {keywords}\\nAnswer:\\n\\n###\\n\\n\",\n",
    "                        #           'completion': f\"{answer} END\"}\n",
    "                        ## ALTERNATIVE W/O CACHE ARRAY ##\n",
    "\n",
    "                        # Appending different arrays to have separate training files\n",
    "                        feeds['all'].append(entry2)\n",
    "                        feeds[skip].append(entry2)\n",
    "                        json.dump(feeds[skip], feedsjson)\n",
    "\n",
    "                    filename = f\"./output_files/{timestamp}_all_{folderpath_stripped}_training.json\"\n",
    "                    with open(filename, mode='w', encoding='utf-8') as feedsjson3:\n",
    "                        json.dump(feeds['all'], feedsjson3)\n",
    "\n",
    "                    ## Save keywords to compare the methods later on\n",
    "                    with open('./output_files/keyword_examples.json', mode='w', encoding='utf-8') as feedsjson2:\n",
    "                        entry2 = {'sentence': f\"{answer}\", 'keywords': keywords_all}\n",
    "                        feeds2.append(entry2)\n",
    "\n",
    "                        # For the whole conversation ##\n",
    "                        json.dump(feeds2, feedsjson2)\n",
    "            cache += f\"Question: {question}\\nAnswer: {answer}\\n\"\n",
    "            cache_array.append(f\"Question: {question}\\nAnswer: {answer}\\n\")\n",
    "        else:\n",
    "            print(\"+++ Skipped the whole file because order was mixed +++\")\n",
    "            print(\"Current: \"+ current +\" line that made it skip: Number: \" + str(counter) + line)\n",
    "            break\n",
    "        counter += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing some stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-08T11:06:42.987911Z",
     "start_time": "2023-06-08T11:06:42.985589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in total: 10\n",
      "Lines in total : 142\n",
      "Empty Lines in total : 28\n",
      "Skipped too long cache : 0\n",
      "Skipped: 0\n",
      "Skipped Too long: 0\n",
      "Not Skipped Answers : 56\n",
      "Not Skipped Questions: 57\n",
      "Keywords counter: {'KeyBERT': 8, 'RAKE': 12, 'YAKE': 17, 'YAKE_DETAILED': 19}\n",
      "History counter: {'0': 19, '1': 18, '2': 8, '3': 11}\n",
      "Length of training split all: 56\n",
      "Length of training split 0: 17\n",
      "Length of training split 2: 23\n",
      "Length of training split 1: 16\n"
     ]
    }
   ],
   "source": [
    "print(\"Files in total: \" + str(files_total))\n",
    "print(\"Lines in total : \" + str(lines_total))\n",
    "print(\"Empty Lines in total : \" + str(empty_line))\n",
    "print(\"Skipped too long cache : \" + str(skipped_too_long_cache))\n",
    "print(\"Skipped: \" + str(skipped))\n",
    "print(\"Skipped Too long: \" + str(skipped_too_long))\n",
    "print(\"Not Skipped Answers : \" + str(not_skipped_answers))\n",
    "print(\"Not Skipped Questions: \" + str(not_skipped_questions))\n",
    "print(\"Keywords counter: \" + str(keywords_counter))\n",
    "print(\"History counter: \" + str(history_counter))\n",
    "for all_elements in (feeds):\n",
    "    print(f\"Length of training split {all_elements}: {len(feeds[all_elements])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
